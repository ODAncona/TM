title,Insights,authors
"Resource Allocation and Workload Scheduling for Large-Scale Distributed
  Deep Learning: A Survey","The paper highlights that distributed training workloads are typically iterative, long-term, and resource-intensive, while inference workloads are one-round, short-term, and lightweight. Efficient operation of computing clusters requires tailored scheduling strategies for each workload type. Although the paper does not specifically evaluate orchestration tools like Slurm, Kubernetes, Flux, and Ray, it emphasizes the importance of resource-aware and workload-aware scheduling to optimize performance in heterogeneous environments, addressing challenges such as network bandwidth allocation and dynamic resource adjustments.","Feng Li, Zhen Zhang, Huadong Lu, Chengming Li, Victor C. M. Leung, Yun Guo, Xiping Hu"
Improving Cluster Utilization Through Adaptive Resource Management for Deep Neural Network and CPU Jobs Colocation,"The paper focuses on improving cluster utilization specifically for deep neural network (DNN) training and inference jobs, rather than comparing orchestration tools like Slurm, Kubernetes, Flux, and Ray. It introduces SODA, a scheduling system that enhances GPU utilization by 19.9% while managing CPU resources effectively for both DNN training and inference workloads. The study emphasizes the importance of CPU core allocation and resource contention in optimizing performance, but does not evaluate the mentioned orchestration tools.","Han Zhao, Weihao Cui, Quan Chen, Jingwen Leng, Deze Zeng, Minyi Guo"
Lyra: Elastic Scheduling for Deep Learning Clusters,"The paper focuses on Lyra, a cluster scheduler designed to optimize the operation of deep learning clusters by addressing the inefficiencies in managing separate training and inference workloads. It highlights the challenges of low utilization in inference clusters and long queuing times for training jobs. While it does not directly compare orchestration tools like Slurm, Kubernetes, Flux, and Ray, it emphasizes the need for effective scheduling strategies to improve resource allocation and job completion times in deep learning environments.","Jiamin Li, Hong Yu Xu, Yibo Zhu, Zherui Liu, Chuanxiong Guo, Cong Wang"
Aryl: An Elastic Cluster Scheduler for Deep Learning,"The paper focuses on the efficient operation of GPU clusters specifically for deep learning, highlighting the challenges of low GPU utilization in inference clusters and long queuing times for training jobs. It introduces Aryl, a scheduler that optimizes resource allocation by implementing capacity loaning and elastic scaling. While it does not evaluate orchestration tools like Slurm, Kubernetes, Flux, or Ray, it operates on top of YARN and Kubernetes, enhancing scheduling efficiency for training and inference workloads.","Jiamin Li, Hong Yu Xu, Yibo Zhu, Zherui Liu, Chuanxiong Guo, Cong Wang"
DynamoML: Dynamic Resource Management Operators for Machine Learning Workloads.,,"Min-Chi Chiang, Jerry Chou"
Research on fusion scheduling based on Slurm and Kubernetes,"The paper focuses on fusion scheduling between Slurm and Kubernetes, addressing the efficient operation of computing clusters specifically for partitioned and hybrid deployment scenarios. It highlights the development of the heterogeneous resource manager Unify, which enhances dynamic node management and resolves resource scheduling conflicts. While it does not directly compare inference versus training workloads or evaluate other orchestration tools like Flux and Ray, it emphasizes improved resource utilization in complex demand scenarios through the integration of Slurm and Kubernetes.","Bo-Lin Wu, Mingming Hu, Shanshan Qin, Jinliang Jiang"
DeepBoot: Dynamic Scheduling System for Training and Inference Deep Learning Tasks in GPU Cluster,"The paper focuses on optimizing GPU cluster utilization for deep learning tasks by addressing the inefficiencies in handling training and inference workloads separately. It highlights the need for dynamic scheduling systems like DeepBoot, which utilizes idle GPUs from inference tasks to enhance training job completion times. While it does not specifically evaluate orchestration tools like Slurm, Kubernetes, Flux, or Ray, it emphasizes the importance of adaptive task scaling and efficient resource allocation in improving overall cluster performance.","Zhenqian Chen, Xinkui Zhao, Chen Zhi, Jianwei Yin"
Running Kubernetes Workloads on HPC,"The paper focuses on running Kubernetes workloads on HPC, specifically using High-Performance Kubernetes (HPK) to bridge the gap between Kubernetes and Slurm for efficient resource management. While it does not directly compare inference versus training workloads or evaluate orchestration tools like Flux and Ray, it emphasizes the practicality of using Slurm for job scheduling alongside Kubernetes for container management, enabling effective hybrid workload deployment in HPC environments with minimal pre-configuration and adherence to existing resource policies.","Antony Chazapis, F. Nikolaidis, Manolis Marazakis, Angelos Bilas"
K8sSim: A Simulation Tool for Kubernetes Schedulers and Its Applications in Scheduling Algorithm Optimization,"The paper focuses on Kubernetes scheduling for short-running workloads, specifically evaluating scheduling algorithms like BRA, LRP, and MRP using real Alibaba cluster traces. While it does not directly compare inference versus training workloads or other orchestration tools like Slurm, Flux, and Ray, it emphasizes the importance of efficient scheduling in Kubernetes to optimize job performance and reduce scheduling time, achieving an average acceleration of 38.56× compared to real clusters.","Shilin Wen, Rui Han, Ke Qiu, Xiaoxin Ma, Zeqing Li, Hongjie Deng, Chi Harold Liu"
"Fine-Grained Scheduling for Containerized HPC Workloads in Kubernetes
  Clusters","The paper focuses on fine-grained scheduling for containerized HPC workloads in Kubernetes, specifically enhancing performance through optimized management frameworks. While it does not directly compare inference versus training workloads or evaluate orchestration tools like Slurm, Flux, and Ray, it highlights the limitations of Kubernetes for HPC applications and introduces scheduling policies that improve efficiency. The study emphasizes the need for tailored scheduling strategies to better manage HPC workloads in cloud environments, particularly through the Scanflow-Kubernetes platform and Volcano scheduler.",
Tear Up the Bubble Boom: Lessons Learned From a Deep Learning Research and Development Cluster,"The paper focuses on the efficient operation of R&D clusters, specifically highlighting the issue of resource underutilization in such environments. While it does not directly compare inference versus training workloads or evaluate orchestration and scheduling tools like Slurm, Kubernetes, Flux, and Ray, it emphasizes the need for tailored scheduling mechanisms for R&D clusters, which differ from production-level clusters. The findings aim to inform better scheduling practices, although specific tool evaluations are not covered in the research.","Zehua Yang, Zhi-Jie Ye, Tianhao Fu, Jing Luo, Xiong Wei, Yingwei Luo, Xiaolin Wang, Zhenlin Wang, Tianwei Zhang"
Scheduling Inference Workloads on Distributed Edge Clusters with Reinforcement Learning,"The paper focuses on scheduling inference workloads on distributed edge clusters, specifically for Deep Neural Networks (DNNs) in edge computing environments. It emphasizes the need for dynamic scheduling policies, like ASET, which adapts to network conditions and workloads, rather than comparing inference to training workloads or evaluating orchestration tools like Slurm, Kubernetes, Flux, and Ray. The primary concern is optimizing inference query scheduling to meet stringent latency and throughput requirements in real-time applications.","Gabriele Castellano, Juan José Nieto, Jordi Luque, Ferran Diego, Carlos Segura, Diego Perino, Flavio Esposito, Fulvio Risso, Aravindh Raman"
EELAS: Energy Efficient and Latency Aware Scheduling of Cloud-Native ML Workloads,"The paper focuses on Energy Efficient Latency-Aware Scheduling (EELAS) specifically for ML inference workloads, rather than comparing inference versus training workloads or evaluating orchestration tools like Slurm, Kubernetes, Flux, and Ray. It highlights the integration of EELAS with Kubernetes to optimize resource allocation for cloud-native ML tasks, emphasizing energy efficiency and latency reduction. However, it does not provide a comparative analysis of different orchestration and scheduling tools or their effectiveness in managing computing clusters.","Ilias Syrigos, Dimitris Kefalas, Nikos Makris, Thanasis Korakis"
Workload-Adaptive Configuration Tuning for Hierarchical Cloud Schedulers,"The paper focuses on AdaptiveConfig, a run-time configuration tuning framework for cluster schedulers, specifically for best-effort cloud jobs. It does not directly compare inference versus training workloads or evaluate orchestration and scheduling tools like Slurm, Kubernetes, Flux, and Ray. Instead, it emphasizes optimizing scheduler configurations to improve job performance and reduce latencies in cloud environments, particularly using YARN Capacity and Fair schedulers with real-world workloads from Facebook and Google.","Rui Han, Chi Harold Liu, Zan Zong, Lydia Y. Chen, Wending Liu, Siyi Wang, Jianfeng Zhan"
HetSev: Exploiting Heterogeneity-Aware Autoscaling and Resource-Efficient Scheduling for Cost-Effective Machine-Learning Model Serving,"The paper focuses on the efficient operation of computing clusters specifically for machine-learning model serving, emphasizing inference workloads rather than training. It extends Kubernetes with a heterogeneity-aware autoscaling mechanism and resource-efficient scheduling to optimize GPU resource utilization. While it does not evaluate orchestration tools like Slurm, Flux, or Ray, it highlights the limitations of traditional cluster schedulers in handling multi-tenant inference, which negatively impacts resource efficiency and serving throughput compared to the proposed HetSev system.","Hao Mo, Ligu Zhu, Lei Shi, Songfu Tan, Suping Wang"
DRAGON: A Dynamic Scheduling and Scaling Controller for Managing Distributed Deep Learning Jobs in Kubernetes Cluster.,"The paper focuses on managing distributed training jobs in Kubernetes clusters, specifically addressing the challenges of resource allocation and execution lifecycle for deep learning workloads. It does not compare inference versus training workloads or evaluate orchestration tools like Slurm, Flux, and Ray. Instead, it enhances Kubernetes with capabilities such as task dependency aware gang scheduling, locality aware task placement, and load aware job scaling, achieving improved resource utilization and reduced job elapsed time compared to the default Kubernetes scheduler.","Chan-Yi Lin, Ting-An Yeh, Jerry Chou"
RLSK: A Job Scheduler for Federated Kubernetes Clusters based on Reinforcement Learning,"The paper focuses on job scheduling in multi-cluster environments using RLSK, a deep reinforcement learning-based scheduler implemented on Kubernetes. It emphasizes efficient scheduling of independent batch jobs without prior knowledge of the workload. While it does not specifically compare inference versus training workloads or evaluate orchestration tools like Slurm, Flux, and Ray, it demonstrates that RLSK outperforms traditional scheduling algorithms, highlighting its effectiveness in optimizing resource allocation and load balancing in federated cloud computing clusters.","Jiaming Huang, Chuming Xiao, Weigang Wu"
KubFBS: A fine‐grained and balance‐aware scheduling system for deep learning tasks based on kubernetes,"The paper focuses on a scheduling system called KubFBS, which enhances the execution of deep learning tasks in Kubernetes by addressing inefficiencies in existing scheduling mechanisms. While it does not directly compare inference versus training workloads or evaluate orchestration tools like Slurm, Flux, and Ray, it emphasizes the importance of fine-grained scheduling and load balancing for deep learning tasks, which can be critical for efficient operation in computing clusters.","Zijie Liu, Can Chen, Junjiang Li, Yi Cheng, Yingjie Kou, Dengyin Zhang"
A Codesign of Scheduling and Parallelization for Large Model Training in Heterogeneous Clusters,"The paper focuses on scheduling and adaptive parallelism for training large models in heterogeneous GPU clusters, specifically through the Crius system. It does not compare inference versus training workloads or evaluate orchestration and scheduling tools like Slurm, Kubernetes, Flux, and Ray. Instead, it emphasizes the integration of adaptive parallelism into cluster scheduling to improve training efficiency, achieving significant reductions in job completion time and enhancements in cluster throughput.","Chunyu Xue, Weihao Cui, Han Zhao, Quan Chen, Shulai Zhang, Peng Yang, Jing Yang, Shaobo Li, Minyi Guo"
Data-Driven Locality-Aware Batch Scheduling,"The paper focuses on improving job scheduling in computing clusters, specifically using the Slurm Workload Manager. It emphasizes a data-aware approach to scheduling that reduces job waiting times and data transfers by keeping large input files in memory. While it does not directly compare inference versus training workloads or evaluate orchestration tools like Kubernetes, Flux, and Ray, it highlights the efficiency gains from its proposed schedulers over traditional methods, demonstrating a 7.5% improvement in job stretch and a 7% decrease in data transfers.","Maxime Gonthier, Elisabeth Larsson, Jean Roman, Carl Nettelblad, Samuel Thibault"
