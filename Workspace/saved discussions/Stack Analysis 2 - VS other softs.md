
# Contexte et objectif

Pour tester différents ordonnanceurs dans un environnement virtuel contrôlé, nous avons besoin d’un cluster de VMs **reproductible** et identique à chaque déploiement. La stack sur-mesure retenue combine : (1) **Hydra** (le système CI de Nix) pour gérer de bout en bout la configuration NixOS ; (2) un wrapper Python utilisant **libvirt** pour créer et administrer les VMs (sans nécessiter d’accès root grâce à Polkit) ; (3) **NixOS** lui-même pour décrire et construire les VMs de manière déclarative et immuable ; (4) un script Python final pour orchestrer le déploiement et lancer la topologie du cluster. Cette approche contraste avec des outils “standard” (Terraform, Ansible, Vagrant) qui, chacun à leur manière, gèrent l’infra et les machines virtuelles. Nous présentons ci-dessous les raisons techniques de ce choix, ses avantages spécifiques et ses limites, ainsi que les cas d’usage où cette solution sur-mesure est pertinente (ou non).

## Raisons techniques du choix de cette stack

- **Pipeline Nix/Hydra :** Hydra est conçu pour fonctionner _au-dessus_ de Nix. Chaque build ou test est exécuté dans un environnement isolé défini par Nix, ce qui assure que les dépendances spécifiques (compilateurs, bibliothèques, utilitaires) sont installées à la version voulue _sans conflits_. Comme le note Sander van der Burg, « Hydra builds on top of Nix… [le gestionnaire Nix] installe automatiquement et à la demande toutes les dépendances requises » et les isole strictement. Autrement dit, la configuration de la pile logicielle (pilotes KVM/QEMU, scripts Python, images ISO NixOS…) reste **déclarative et reproductible** via Nix, et Hydra orchestre le tout dans un pipeline CI/CD unifié.
    
- **Wrapper Python + libvirt (sans sudo) :** Plutôt que d’utiliser un outil générique comme Terraform ou Vagrant, nous avons choisi d’écrire notre propre couche d’abstraction Python sur libvirt. Cela permet un **contrôle fin et programmatique** de la création des VMs (définir dynamiquement le nombre de nœuds, leur réseau, mémoire, CPU, etc.) via une API bien connue. Comme le souligne Thorsten Scherf, « si vous ne voulez pas utiliser les cadres de gestion de VM majeurs, la librairie libvirt pour Python offre une alternative ». Avec des règles Polkit appropriées (par exemple autoriser le groupe Linux « wheel » à gérer libvirt), l’utilisateur Python peut manipuler libvirt sans être root. Cela évite de devoir exécuter Terraform/libvirt avec sudo, simplifie l’intégration dans des environnements sécurisés (CI, serveurs partagés) et limite les droits. En comparaison, le _provider_ Terraform pour libvirt exige également un accès au démon libvirt, souvent configuré via Polkit, et introduit une couche supplémentaire (HCL + binaire Go) qui est moins flexible pour du script sur mesure.
    
- **NixOS pour la généricité et la reproductibilité** : Chaque machine du cluster est décrite via NixOS, ce qui garantit que le système d’exploitation complet (du noyau aux services) correspond exactement à la spécification Nix. Comme l’explique un contributeur sur Hacker News, « NixOS… n’est pas seulement reproductible, l’OS sera le reflet complet de vos spécifications Nix ». Autrement dit, on ne monte pas une VM avec une Debian+Ansible ou un VBox box arbitraire, mais on génère l’image NixOS à partir d’un fichier de configuration versionné. Cela rend le cluster _immuable_ et **contrôlable en version** : on peut recréer le même cluster des années plus tard, sur n’importe quel hôte, en reprenant exactement le même code Nix et la même chaîne Hydra. De plus, l’isolement par Nix signifie qu’un Garbage Collection peut nettoyer les dépendances inutilisées sans casser les builds existants.
    
- **Orchestration Python finale :** Le script Python qui orchestre le workflow final (après génération des définitions NixOS) offre encore plus de flexibilité que des outils déclaratifs purs. Il peut enchaîner des étapes complexes (génération d’images NixOS, création réseau libvirt, lancement des VMs, tests de connectivité, etc.) dans l’ordre voulu, avec de la logique conditionnelle ou des boucles si nécessaire. Cette approche impérative permet notamment d’implémenter des cas particuliers spécifiques au projet qui seraient laborieux en HCL ou en YAML.
    

## Avantages spécifiques de cette approche

- **Reproductibilité et isolation complète :** Grâce à Nix et Hydra, toute la pile est construite de façon déterministe. Par exemple, lors de tests d’intégration, « un nouvel environnement frais » est recréé à chaque lancement de test, ce qui élimine les effets de bord. Dans notre cas, chaque topologie de cluster est définie par du code et refabriquée identique à chaque run. Comme le note Jonas Chevalier, « NixOS a montré que l’utilisation de Nix avec des VMs QEMU pour l’isolation est un concept puissant. Cela rend simple le lancement d’environnements frais tout en gardant la variance entre les exécutions faible ».
    
- **Contrôle granulaire et adaptabilité :** Le wrapper Python sur libvirt permet de moduler très finement la configuration des VMs, leurs réseaux, leur stockage, etc., sans être limité par le périmètre d’un provider pré-existant. Il est par ailleurs aisé d’intégrer des outils ou modules Python tiers pour surveiller ou ajuster dynamiquement le cluster. On peut aussi réutiliser les mêmes compétences (Python, libvirt) sur un serveur CI ou un poste développeur sans changer d’outil. Enfin, le fait de ne pas nécessiter de sudo (via Polkit) ouvre la possibilité d’exécuter ces scripts dans des contextes contraints (ex. serveurs CI où l’utilisateur n’a pas tous les droits) sans bricolage.
    
- **Adaptation aux environnements contraints :** Si le contexte impose de ne pas installer Java/VM (par exemple Jenkins/Hudson en Go pour Terraform) ou d’avoir des règles strictes sur les permissions, la combinaison NixOS+Hydra+libvirt Python permet de contourner ces limites. Hydra et Nix reposent sur des techniques de cache binaire (substituts) et fonctionnent bien hors ligne dès lors qu’on a préconstruit les paquets, ce qui n’est pas toujours possible avec Ansible/Terraform par défaut.
    
- **Intégration du développement et CI :** Cette pile tire parti des workflows Nix/Hydra : par exemple, chaque changement de configuration du cluster peut déclencher automatiquement une reconstruction Hydra, assurant que les modifications sont testées avant déploiement. On bénéficie ainsi d’un pipeline _« holistique »_ où la configuration, la build de l’OS, la création des VMs et les tests sont liés fonctionnellement, sans scripts ad hoc dispersés.
    

## Faiblesses et limites par rapport aux outils existants

- **Écosystème et standardisation réduits :** Contrairement à Terraform (plus de **3 000 providers** officiels/communautaires) ou à Ansible/Vagrant, notre solution sur-mesure n’a pas de large bibliothèque de modules prêts à l’emploi. Par exemple, Terraform propose déjà des modules comme _terraform-nixos_ pour NixOS, ou d’innombrables roles Ansible pour configurer Kubernetes/SlaManager, etc. Notre code Python/libvirt est spécifique au projet et devra être maintenu en interne. De même, la stack Nix/Hydra est moins familière : les nouveaux arrivants peuvent avoir une forte courbe d’apprentissage.
    
- **Effort initial important :** Mettre en place Hydra, apprivoiser Nix (surtout Flakes ou modules NixOS) et écrire le wrapper Python demandent du temps et des compétences. C’est indéniablement plus lourd qu’un simple `Vagrantfile` ou playbook Ansible, surtout si l’équipe n’est pas déjà rompu à Nix. En pratique, il faut configurer Hydra (base de données, slaves de build si besoin, règles de Polkit pour libvirt…), installer Nix sur l’hôte, etc. De plus, contrairement à Terraform/Ansible qui ont une vaste communauté et de la documentation, les cas d’usage NixOS/Hydra sont plus pointus, ce qui peut ralentir le support et l’intégration d’éléments nouveaux.
    
- **Rigidité du monde NixOS :** Notre approche est centrée sur Linux/NixOS. Si l’on voulait inclure d’autres OS (Windows, etc.), Nix n’est pas prévu pour cela, contrairement à Terraform/Ansible multi-OS. De même, le model NixOS repose sur un paradigme fonctionnel : modifier un paramètre OS nécessite souvent de reconstruire/réinstaller la machine, ce qui est plus rigide qu’un playbook Ansible pouvant patcher en direct.
    
- **Maintenance de la solution custom :** En interne, chaque bug ou limitation du wrapper Python doit être géré par nos soins. Par exemple, nous devons maintenir notre gestion des réseaux libvirt ou des images NixOS. Cela peut être perçu comme réinventer la roue pour des fonctionnalités basiques que Vagrant ou Terraform fournissent (réseau en pont, NAT, etc.). On perd aussi la possibilité de « passer à la version supérieure » d’un outil externe qui corrige automatiquement certains problèmes (nous dépendons de nos propres mises à jour).
    

## Cas d’usage : quand cette approche est pertinente

- **Environnements de test/CI avancés** où la **reproductibilité absolue** est cruciale. Par exemple, des laboratoires de recherche ou DevOps cherchant à comparer des ordonnanceurs sur des scénarios identiques (chaque test démarre avec une topologie fraîche définie par code). Dans ces contextes, garantir que l’OS et les versions logicielles n’ont jamais changé entre deux runs est un atout majeur, et NixOS+Hydra offre cela « out of the box ».
    
- **Contraintes d’accès/root** : Sur une infrastructure partagée (serveurs de build CI, serveurs d’entreprise à privilèges restreints), le fait de pouvoir créer des VMs via libvirt **sans sudo** (via Polkit) et de déployer NixOS en local est un avantage. Terraform et Ansible peuvent nécessiter des comptes de service privilégiés ou des jumps, ce qui complique la mise en place dans certains cadres sécurisés.
    
- **Utilisation existante de Nix/NixOS/Hydra** : Si l’équipe est déjà familière avec Nix, elle tirera rapidement profit de l’approche (ou si le code d’infra est déjà géré en Nix). Il est alors logique d’étendre l’usage à la configuration du cluster.
    
- **Besoin de flexibilité métier** : Si l’on doit intégrer des étapes spécifiques (préparation de data, instrumentation des VMs, collecte de logs custom) au sein du pipeline de déploiement, un script Python général peut être plus simple à adapter qu’un playbook Ansible ou du HCL figé.
    

## Cas d’usage : quand privilégier Terraform/Vagrant (ou Ansible)

- **Infrastructure multi-plateformes ou cloud** : Pour déployer sur le cloud public (AWS, Azure, GCP) ou mélanger plusieurs hyperviseurs, Terraform dispose d’un vaste écosystème (3000+ providers) et est dédié à l’IaC. Notre approche libvirt/Python est limitée à KVM/QEMU sur Linux. Si on doit travailler avec VMware, AWS EC2, ou des hôtes Windows, Terraform est plus adapté.
    
- **Développement local simple** : Si l’objectif est juste de fournir rapidement des environnements de développement ou de test pour quelques développeurs, Vagrant est très simple : un `Vagrantfile` Ruby suffit pour déclarer une VM « standard », et de nombreux box (Ubuntu, CentOS, etc.) sont déjà préparés. Vagrant assure l’identité de l’environnement (« everybody vagrant up ») comme le souligne un tutoriel : « en utilisant un Vagrantfile pour définir l’environnement, les développeurs peuvent s’assurer que leurs environnements sont identiques, quel que soit le système/hardware sous-jacent ». Vagrant intègre des mécanismes de provisionnement (Ansible/Chef/puppet) pour le haut niveau, mais ne fabrique pas l’image OS. Par conséquent, pour des besoins plus « standard », Vagrant sera plus rapide à mettre en œuvre.
    
- **Gestion de configuration et patchs incrémentaux** : Ansible excelle pour des adaptations post-déploiement (installer des paquets, modifier des configs dans des VMs existantes). Si notre besoin n’est que de paramétrer des VMs (après création) ou de déployer des applications, Ansible (ou Puppet/Chef) est plus direct, alors que NixOS nécessite de redéployer la machine pour changer un paquet ou une option système. Terraform et Vagrant combinés à Ansible sont souvent préférables pour une gestion _continuer_ d’infrastructure en production (par ex. mise à jour d’un serveur en ligne) plutôt que la récréation complète de la VM.
    
- **Pérennité et compétences de l’équipe** : Si l’équipe est déjà formée aux outils standards (HashiCorp, ansible), il peut être préférable d’éviter la complexité Nix/Hydra, surtout pour des projets de courte durée ou nécessitant un partage large. Terraform et Vagrant bénéficient d’une large communauté, de nombreux exemples et plugins (containers, cloud, réseau virtualisé), donc en termes de ressources et de fiabilité, ils sont souvent plus rassurants pour un déploiement « en production ».
    

## Synthèse des compromis

En somme, la stack **NixOS+Hydra+Python/libvirt** vise un contrôle maximal et une reproductibilité totale au prix d’un certain investissement initial et d’une moindre standardisation. Elle est **supérieure** lorsque la précision, l’isolation et la répétabilité sont essentielles (tests rigoureux de performance, clusters HPC dédiés, contraintes de sécurité). En revanche, pour des scénarios plus génériques ou pilotés vers le cloud/deploiement rapide, les solutions éprouvées (Terraform pour l’infra déclarative, Vagrant pour les VMs dev, Ansible pour la config) restent souvent plus pratiques. Le choix dépend finalement du contexte : **s’assurer que les gains en fiabilité et en contrôle valent le surcoût d’effort et de spécialisation**, et ne pas sacrifier la simplicité là où un outil standard est suffisant.

**Sources :** Comparaisons techniques issues notamment des documentations Nix/Hydra et publications communautaires sur l’IaC, ainsi que de retours d’expérience liés à NixOS vs Terraform/Vagrant.